#!/usr/bin/env python3
"""
FlexOlmoè¯„æµ‹ç¯å¢ƒæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯è¯„æµ‹ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®

è¿è¡Œæ–¹å¼:
python test_eval_setup.py /path/to/FlexOlmo-7x7B-1T
"""

import sys
import os
import logging
from pathlib import Path

def test_python_imports():
    """æµ‹è¯•å¿…è¦çš„PythonåŒ…å¯¼å…¥"""
    print("1. æµ‹è¯•PythonåŒ…å¯¼å…¥...")
    
    required_packages = [
        ('torch', 'PyTorch'),
        ('transformers', 'Transformers'),
        ('datasets', 'Datasets'),
        ('json', 'JSON (å†…ç½®)'),
    ]
    
    all_ok = True
    for package, name in required_packages:
        try:
            __import__(package)
            print(f"  âœ… {name} - å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            print(f"  âŒ {name} - å¯¼å…¥å¤±è´¥: {e}")
            all_ok = False
    
    return all_ok

def test_model_files(model_path):
    """æµ‹è¯•æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print(f"\n2. æµ‹è¯•æ¨¡å‹æ–‡ä»¶: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"  âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return False
    
    required_files = [
        'config.json',
        'tokenizer.json', 
        'tokenizer_config.json',
        'model.safetensors.index.json'
    ]
    
    all_ok = True
    for file_name in required_files:
        file_path = os.path.join(model_path, file_name)
        if os.path.exists(file_path):
            print(f"  âœ… {file_name} - å­˜åœ¨")
        else:
            print(f"  âŒ {file_name} - ä¸å­˜åœ¨")
            all_ok = False
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    safetensors_files = list(Path(model_path).glob("model-*.safetensors"))
    if safetensors_files:
        print(f"  âœ… æ¨¡å‹æƒé‡æ–‡ä»¶ - æ‰¾åˆ° {len(safetensors_files)} ä¸ªæ–‡ä»¶")
    else:
        print(f"  âŒ æ¨¡å‹æƒé‡æ–‡ä»¶ - æœªæ‰¾åˆ° .safetensors æ–‡ä»¶")
        all_ok = False
    
    return all_ok

def test_cuda_availability():
    """æµ‹è¯•CUDAå¯ç”¨æ€§"""
    print("\n3. æµ‹è¯•CUDAæ”¯æŒ...")
    
    try:
        import torch
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            print(f"  âœ… CUDAå¯ç”¨ - {device_count} ä¸ªGPUè®¾å¤‡")
            
            for i in range(device_count):
                gpu_name = torch.cuda.get_device_name(i)
                memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                print(f"    GPU {i}: {gpu_name} ({memory:.1f} GB)")
            
            return True
        else:
            print("  âš ï¸  CUDAä¸å¯ç”¨ - å°†ä½¿ç”¨CPU (é€Ÿåº¦è¾ƒæ…¢)")
            return True
    except Exception as e:
        print(f"  âŒ CUDAæ£€æµ‹å¤±è´¥: {e}")
        return False

def test_data_loader():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print("\n4. æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    
    try:
        # å°è¯•å¯¼å…¥æ•°æ®åŠ è½½å™¨
        sys.path.append('src/rag')
        from data_loader import MUSENewsDataLoader
        
        print("  âœ… æ•°æ®åŠ è½½å™¨å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºåŠ è½½å™¨å®ä¾‹
        loader = MUSENewsDataLoader() 
        print("  âœ… æ•°æ®åŠ è½½å™¨å®ä¾‹åŒ–æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        print(f"  âŒ æ•°æ®åŠ è½½å™¨å¯¼å…¥å¤±è´¥: {e}")
        print("  ğŸ’¡ è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
        return False
    except Exception as e:
        print(f"  âŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_huggingface_auth():
    """æµ‹è¯•Hugging Faceè®¤è¯"""
    print("\n5. æµ‹è¯•Hugging Faceè®¤è¯...")
    
    try:
        from huggingface_hub import whoami
        
        try:
            user_info = whoami()
            print(f"  âœ… å·²ç™»å½•Hugging Face: {user_info.get('name', 'unknown')}")
            return True
        except Exception:
            print("  âš ï¸  æœªç™»å½•Hugging Face")
            print("  ğŸ’¡ è¿è¡Œä»¥ä¸‹å‘½ä»¤ç™»å½•:")
            print("     huggingface-cli login")
            print("     æˆ–è®¾ç½®: export HF_TOKEN='your-token'")
            return False
            
    except ImportError:
        print("  âŒ huggingface_hubæœªå®‰è£…")
        return False

def test_memory_estimation():
    """ä¼°ç®—å†…å­˜éœ€æ±‚"""
    print("\n6. å†…å­˜éœ€æ±‚æ£€æŸ¥...")
    
    try:
        import psutil
        
        # è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        total_gb = memory.total / (1024**3)
        available_gb = memory.available / (1024**3)
        
        print(f"  ç³»ç»Ÿæ€»å†…å­˜: {total_gb:.1f} GB")
        print(f"  å¯ç”¨å†…å­˜: {available_gb:.1f} GB")
        
        # FlexOlmo-7x7B-1Tå¤§çº¦éœ€è¦24GBå†…å­˜
        required_gb = 24
        
        if available_gb >= required_gb:
            print(f"  âœ… å†…å­˜å……è¶³ (éœ€è¦çº¦{required_gb}GB)")
        else:
            print(f"  âš ï¸  å†…å­˜å¯èƒ½ä¸è¶³ (éœ€è¦çº¦{required_gb}GB)")
            print("  ğŸ’¡ å»ºè®®:")
            print("     - å…³é—­å…¶ä»–ç¨‹åºé‡Šæ”¾å†…å­˜")
            print("     - ä½¿ç”¨è¾ƒä½ç²¾åº¦ (float16)")
            print("     - è€ƒè™‘ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬")
        
        return True
        
    except ImportError:
        print("  âŒ psutilæœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥å†…å­˜")
        return False
    except Exception as e:
        print(f"  âŒ å†…å­˜æ£€æŸ¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("FlexOlmoè¯„æµ‹ç¯å¢ƒæµ‹è¯•")
    print("=" * 50)
    
    if len(sys.argv) < 2:
        print("âŒ è¯·æä¾›FlexOlmoæ¨¡å‹è·¯å¾„")
        print("ç”¨æ³•: python test_eval_setup.py /path/to/FlexOlmo-7x7B-1T")
        sys.exit(1)
    
    model_path = sys.argv[1]
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        test_python_imports,
        lambda: test_model_files(model_path),
        test_cuda_availability,
        test_data_loader,
        test_huggingface_auth,
        test_memory_estimation
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed_tests += 1
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 50)
    print(f"é€šè¿‡æµ‹è¯•: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! ç¯å¢ƒé…ç½®æ­£ç¡®")
        print("\næ¥ä¸‹æ¥å¯ä»¥è¿è¡Œ:")
        print(f"python src/rag/eval_FlexOlmo.py {model_path}")
    elif passed_tests >= total_tests - 2:
        print("âš ï¸  å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥å°è¯•è¿è¡Œè¯„æµ‹")
        print("å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·å‚è€ƒä¸Šè¿°é”™è¯¯ä¿¡æ¯è¿›è¡Œä¿®å¤")
    else:
        print("âŒ å¤šé¡¹æµ‹è¯•å¤±è´¥ï¼Œè¯·å…ˆä¿®å¤ç¯å¢ƒé…ç½®")
        print("å‚è€ƒ FlexOlmo_Evaluation_Guide.md è·å–è¯¦ç»†è¯´æ˜")

if __name__ == "__main__":
    main()